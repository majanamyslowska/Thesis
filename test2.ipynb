{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test (miniconda3 (Python 3.12.2), open integrated terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.48, 35.55, 37.07, 36.98, 37.69, 38.33, 38.45, 38.07, 37.5, 38.27, 38.74, 38.97, 39.21, 38.33, 38.48, 38.18, 39.44, 39.08, 38.67, 41.31, 41.61, 41.63, 42.81, 43.55, 43.56, 42.74, 42.6, 42.36, 42.72, 42.55, 42.7, 42.61, 42.73, 43.01, 42.77, 43.24, 43.56, 43.58, 43.72, 43.29, 43.74, 43.96, 43.88, 43.63, 43.13, 43.23, 44.73, 45.23, 45.43, 45.93, 46.53, 47.01, 46.63, 47.04, 48.77, 47.76, 47.19, 46.7, 47.12, 47.18, 47.49, 47.81, 48.51, 48.84, 48.92, 49.25, 50.03, 49.88, 50.16, 49.74, 49.72, 49.81, 49.81, 50.78, 50.97, 51.13, 51.87, 51.79, 51.32, 51.08, 51.15, 50.17, 52.63, 52.29, 52.94, 52.12, 50.72, 50.73, 50.18, 49.3, 46.43, 47.17, 47.73, 47.52, 47.25, 45.77, 46.65, 45.7, 44.92, 44.74, 44.56, 44.35, 44.58, 43.77, 43.33, 44.91, 45.64, 46.31, 47.54, 48.15, 48.7, 48.55, 48.54, 48.19, 48.47, 49.61, 49.47, 49.87, 49.7, 49.65, 48.89, 49.95, 49.94, 49.48, 50.39, 50.68, 51.1, 51.06, 50.01, 50.31, 50.81, 50.44, 50.83, 51.3, 51.13, 50.84, 51.42, 50.65, 51.81, 52.21, 52.17, 51.76, 51.94, 52.42, 52.2, 53.26, 52.11, 51.01, 48.34, 49.25, 49.76, 50.86, 50.25, 50.12, 52.24, 50.69, 50.44, 51.63, 52.59, 52.59, 53.16, 53.12, 50.66, 51.62, 51.04, 51.38, 52.25, 52.19, 51.43, 52.3, 53.32, 53.32, 53.54, 54.18, 55.9, 55.77, 54.69, 54.98, 55.18, 55.69, 55.24, 54.43, 54.68, 54.42, 55.26, 54.97, 54.71, 55.99, 56.15, 54.74, 55.21, 56.75, 56.77, 56.1, 56.76, 57.52, 59.05, 58.97, 58.83, 58.59, 58.82, 59.1, 60.13, 59.99, 60.8, 60.9, 61.65, 62.26, 60.82, 60.82, 62.19, 63.96, 64.38, 64.28, 64.31, 64.86, 65.04, 65.55, 65.49, 66.12, 65.66, 66.44, 66.78, 66.57, 65.8, 65.5, 65.45, 66.59, 66.07, 66.96, 66.81, 66.04, 64.86, 65.44, 66.4, 67.68, 66.73, 67.12, 67.69, 67.87, 68.79, 69.97, 70.1, 69.94, 70.01, 69.86, 71.0, 71.07, 72.48, 72.45, 72.88, 73.41, 75.09, 74.36, 74.95, 74.6, 75.8, 77.41, 77.58, 79.24, 78.17, 77.84, 78.81, 79.68, 79.14, 79.43, 79.81, 79.58, 77.24, 79.42, 81.09, 80.97, 77.38, 77.17, 79.71, 80.36, 81.3, 80.01, 80.39, 79.9, 81.8, 81.22, 81.24, 79.75, 80.91, 80.08, 78.26, 74.55, 72.02, 73.16, 68.38, 68.34, 74.7, 72.33, 75.69, 73.23, 72.26, 66.54, 71.34, 68.86, 62.06, 69.49, 60.55, 63.22, 61.67, 61.2, 57.31, 56.09, 61.72, 61.38, 64.61, 61.94, 63.7, 63.57, 60.23, 61.23, 60.35, 65.62, 64.86, 66.52, 67.0, 68.31, 71.76, 71.11, 71.67, 70.7, 69.23, 67.09, 69.03, 68.76, 70.74, 70.79, 69.65, 71.93, 73.45, 72.27, 73.29, 74.39, 75.16, 75.94, 77.53, 78.75, 77.85, 76.91, 77.39, 76.93, 78.74, 78.29, 79.81, 79.21, 79.72, 79.18, 79.53, 79.56, 79.49, 80.46, 80.84, 81.28, 80.58, 82.88, 83.37, 86.0, 88.21, 83.98, 84.7, 85.75, 88.02, 87.9, 87.93, 87.43, 89.72, 91.63, 90.02, 91.21, 88.41, 90.45, 91.2, 91.03, 91.03, 93.46, 93.17, 95.34, 95.68, 95.92, 95.48, 97.06, 97.73, 96.52, 96.33, 98.36, 97.0, 97.27, 92.85, 92.62, 94.81, 93.25, 95.04, 96.19, 106.26, 108.94, 109.67, 110.06, 113.9, 111.11, 112.73, 109.38, 113.01, 115.01, 114.91, 114.61, 115.56, 115.71, 118.28, 124.37, 125.86, 124.83, 126.52, 125.01, 124.81, 129.04, 134.18, 131.4, 120.88, 120.96, 112.82, 117.32, 113.49, 112.0, 115.36, 115.54, 112.13, 110.34, 106.84, 110.08, 111.81, 107.12, 108.22, 112.28, 114.96, 114.09, 115.81, 116.79, 113.02, 116.5, 113.16, 115.08, 114.97, 116.97, 124.4, 121.1, 121.19, 120.71, 119.02, 115.98, 117.51, 116.87, 115.75, 115.04, 115.05, 116.6, 111.2, 115.32, 108.86, 108.77, 110.44, 114.95, 119.03, 118.69, 116.32, 115.97, 119.49, 119.21, 119.26, 120.3, 119.39, 118.03, 118.64, 117.34, 113.85, 115.17, 116.03, 116.59, 119.05, 122.72, 123.08, 122.94, 122.25, 123.75, 124.38, 121.78, 123.24, 122.41, 121.78, 127.88, 127.81, 128.7, 126.66, 128.23, 131.88, 130.96, 131.97, 136.69, 134.87, 133.72, 132.69, 129.41, 131.01, 126.6, 130.92, 132.05, 128.98, 128.8, 130.89, 128.91, 127.14, 127.83, 132.03, 136.87, 139.07, 142.92, 143.16, 142.06, 137.09, 131.96, 134.14, 134.99, 133.94, 137.39, 136.76, 136.91, 136.01, 135.39, 135.13, 135.37, 133.19, 130.84, 129.71, 129.87, 126.0, 125.86, 125.35, 120.99, 121.26, 127.79, 125.12, 122.06, 120.13, 121.42, 116.36, 121.09, 119.98, 121.96, 121.03, 123.99, 125.57, 124.76, 120.53, 119.99, 123.39, 122.54, 120.09, 120.59, 121.21, 121.39, 119.9, 122.15, 123.0, 125.9, 126.21, 127.9, 130.36, 133.0, 131.24, 134.43, 132.03, 134.5, 134.16, 134.84, 133.11, 133.5, 131.94, 134.32, 134.72, 134.39, 133.58, 133.48, 131.46, 132.54, 127.85, 128.1, 129.74, 130.21, 126.85, 125.91, 122.77, 124.97, 127.45, 126.27, 124.85, 124.69, 127.31, 125.43, 127.1, 126.9, 126.85, 125.28, 124.61, 124.28, 125.06, 123.54, 125.89, 125.9, 126.74, 127.13, 126.11, 127.35, 130.48, 129.64, 130.15, 131.79, 130.46, 132.3, 133.98, 133.7, 133.41, 133.11, 134.78, 136.33, 136.96, 137.27, 139.96, 142.02, 144.57, 143.24, 145.11, 144.5, 145.64, 149.15, 148.48, 146.39, 142.45, 146.15, 145.4, 146.8, 148.56, 148.99, 146.77, 144.98, 145.64, 145.86, 145.52, 147.36, 146.95, 147.06, 146.14, 146.09, 145.6, 145.86, 148.89, 149.1, 151.12, 150.19, 146.36, 146.7, 148.19, 149.71, 149.62, 148.36, 147.54, 148.6, 153.12, 151.83, 152.51, 153.65, 154.3, 156.69, 155.11, 154.07, 148.97, 149.55, 148.12, 149.03, 148.79, 146.06, 142.94, 143.43, 145.85, 146.83, 146.92, 145.37, 141.91, 142.83, 141.5, 142.65, 139.14, 141.11, 142.0, 143.29, 142.9, 142.81, 141.51, 140.91, 143.76, 144.84, 146.55, 148.76, 149.26, 149.48, 148.69, 148.64, 149.32, 148.85, 152.57, 149.8, 148.96, 150.02, 151.49, 150.96, 151.28, 150.44, 150.81, 147.92, 147.87, 149.99, 150.0, 151.0, 153.49, 157.87, 160.55, 161.02, 161.41, 161.94, 156.81, 160.24, 165.3, 164.77, 163.76, 161.84, 165.32, 171.18, 175.08, 174.56, 179.45, 175.74, 174.33, 179.3, 172.26, 171.14, 169.75, 172.99, 175.64, 176.28, 180.33, 179.29, 179.38, 178.2, 177.57, 182.01, 179.7, 174.92, 172.0, 172.17, 172.19, 175.08, 175.53, 172.19, 173.07, 169.8, 166.23, 164.51, 162.41, 161.62, 159.78, 159.69, 159.22, 170.33, 174.78, 174.61, 175.84, 172.9, 172.39, 171.66, 174.83, 176.28, 172.12, 168.64, 168.88, 172.79, 172.55, 168.88, 167.3, 164.32, 160.07, 162.74, 164.85, 165.12, 163.2, 166.56, 166.23, 163.17, 159.3, 157.44, 162.95, 158.52, 154.73, 150.62, 155.09, 159.59, 160.62, 163.98, 165.38, 168.82, 170.21, 174.07, 174.72, 175.6, 178.96, 177.77, 174.61, 174.31, 178.44, 175.06, 171.83, 172.14, 170.09, 165.75, 167.66, 170.4, 165.29, 165.07, 167.4, 167.23, 166.42, 161.79, 162.88, 156.8, 156.57, 163.64, 157.65, 157.96, 159.48, 166.02, 156.77, 157.28, 152.06, 154.51, 146.5, 142.56, 147.11, 145.54, 149.24, 140.82, 137.35, 137.59, 143.11, 140.36, 140.52, 143.78, 149.64, 148.84, 148.71, 151.21, 145.38, 146.14, 148.71, 147.96, 142.64, 137.13, 131.88, 132.76, 135.43, 130.06, 131.56, 135.87, 135.35, 138.27, 141.66, 141.66, 137.44, 139.23, 136.72, 138.93, 141.56, 142.92, 146.35, 147.04, 144.87, 145.86, 145.49, 148.47, 150.17, 147.07, 151.0, 153.04, 155.35, 154.09, 152.95, 151.6, 156.79, 157.35, 162.51, 161.51, 160.01, 166.13, 165.81, 165.35, 164.87, 164.92, 169.24, 168.49, 172.1, 173.19, 173.03, 174.55, 174.15, 171.52, 167.57, 167.23, 167.53, 170.03, 163.62, 161.38, 158.91, 157.22, 157.96, 155.81, 154.53, 155.96, 154.46, 157.37, 163.43, 153.84, 155.31, 152.37, 150.7, 154.48, 156.9, 153.72, 152.74, 150.43, 150.77, 151.76, 149.84, 142.48, 138.2, 142.45, 146.1, 146.4, 145.43, 140.09, 140.42, 138.98, 138.34, 142.99, 138.38, 142.41, 143.75, 143.86, 143.39, 147.27, 149.45, 152.34, 149.35, 144.8, 155.74, 153.34, 150.65, 145.03, 138.88, 138.38, 138.92, 139.5, 134.87, 146.87, 149.7, 148.28, 150.04, 148.79, 150.72, 151.29, 148.01, 150.18, 151.07, 148.11, 144.22, 141.17, 148.03, 148.31, 147.81, 146.63, 142.91, 140.94, 142.65, 142.16, 144.49, 145.47, 143.21, 136.5, 134.51, 132.37, 132.3, 135.45, 132.23, 131.86, 130.03, 126.04, 129.61, 129.93, 125.07, 126.36, 125.02, 129.62, 130.15, 130.73, 133.49, 133.41, 134.76, 135.94, 135.21, 135.27, 137.87, 141.11, 142.53, 141.86, 143.96, 145.93, 143.0, 144.29, 145.43, 150.82, 154.5, 151.73, 154.65, 151.92, 150.87, 151.01, 153.85, 153.2, 155.33, 153.71, 152.55, 148.48, 148.91, 149.4, 146.71, 147.92, 147.41, 145.31, 145.91, 151.03, 153.83, 151.6, 152.87, 150.59, 148.5, 150.47, 152.59, 152.99, 155.85, 155.0, 157.4, 159.28, 157.83, 158.93, 160.25, 158.28, 157.65, 160.77, 162.36, 164.9, 166.17, 165.63, 163.76, 164.66, 162.03, 160.8, 160.1, 165.56, 165.21, 165.23, 166.47, 167.63, 166.65, 165.02, 165.33, 163.77, 163.76, 168.41, 169.68, 169.59, 168.54, 167.45, 165.79, 173.57, 173.5, 171.77, 173.56, 173.75, 172.57, 172.07, 172.07, 172.69, 175.05, 175.16, 174.2, 171.56, 171.84, 172.99, 175.43, 177.3, 177.25, 180.09, 180.95, 179.58, 179.21, 177.82, 180.57, 180.96, 183.79, 183.31, 183.95, 186.01, 184.92, 185.01, 183.96, 187.0, 186.68, 185.27, 188.06, 189.25, 189.59, 193.97, 192.46, 191.33, 191.81, 190.68, 188.61, 188.08, 189.77, 190.54, 190.69, 193.99, 193.73, 195.1, 193.13, 191.94, 192.75, 193.62, 194.5, 193.22, 195.83, 196.45, 195.61, 192.58, 191.17, 181.99, 178.85, 179.8, 178.19, 177.97, 177.79, 179.46, 177.45, 176.57, 174.0, 174.49, 175.84, 177.23, 181.12, 176.38, 178.61, 180.19, 184.12, 187.65, 187.87, 189.46, 189.7, 182.91, 177.56, 178.18, 179.36, 176.3, 174.21, 175.74, 175.01, 177.97, 179.07, 175.49, 173.93, 174.79, 176.08, 171.96, 170.43, 170.69, 171.21, 173.75, 172.4, 173.66, 174.91, 177.49, 178.99, 178.39, 179.8, 180.71, 178.85, 178.72, 177.15, 175.84, 175.46, 172.88, 173.0, 173.44, 171.1, 166.89, 168.22, 170.29, 170.77, 173.97, 177.57, 176.65, 179.23, 181.82, 182.89, 182.41, 186.4, 184.8, 187.44, 188.01, 189.71, 189.69, 191.45, 190.64, 191.31, 189.97, 189.79, 190.4, 189.37, 189.95, 191.24, 189.43, 193.42, 192.32, 194.27, 195.71, 193.18, 194.71, 197.96, 198.11, 197.57, 195.89, 196.94, 194.83, 194.68, 193.6, 193.05, 193.15, 193.58, 192.53]\n"
     ]
    }
   ],
   "source": [
    "# format prices into lists\n",
    "close_prices = []\n",
    "data = []\n",
    "open_prices = []\n",
    "\n",
    "with open('./data/prices/csvs/AAPL.csv', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        data.append(float(row[1]))\n",
    "\n",
    "data.reverse()\n",
    "print(data)\n",
    "\n",
    "# for i in range(0,10):\n",
    "#     if close_prices[i+5] > close_prices[i+4]:\n",
    "#         m = 'up'\n",
    "#     else:\n",
    "#         m = 'down'\n",
    "#     print(close_prices[i:i+5], close_prices[i+5], m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Close Price'])\n",
    "\n",
    "df['Date'] = pd.date_range(start='2023-07-01', periods=len(data), freq='D')\n",
    "\n",
    "df['Moving Average'] = df['Close Price'].rolling(window=21).mean()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(df['Date'], df['Close Price'], label='Close Price', marker='.', markersize=4, linewidth=1)\n",
    "plt.plot(df['Date'], df['Moving Average'], label='21-Day Moving Average', linestyle='--', linewidth=1)\n",
    "\n",
    "plt.title('Close Price and Moving Average')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "LANGCHAIN_TRACING_V2 = os.getenv(\"LANGCHAIN_TRACING_V2\")\n",
    "LANGCHAIN_API_KEY = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import openai\n",
    "import getpass\n",
    "import os\n",
    "import langchainhub\n",
    "from langchain import hub\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"2+2=\"\n",
    "            # \"content\": \"these are the stock prices (closing price) from past 5 days: [37.07, 36.98, 37.69, 38.33, 38.45], last element of the list is the latest closing price. these are the news headlines relating to the stock's company: ['may have reached its all time high', 'is the stock price going to fall?']. predict if the stock price next day will go up or down. your answer should either be up or down, do not elaborate.\",\n",
    "            # \"content\": \"these are the stock prices (closing price) from past 5 days: [37.07, 36.98, 37.69, 38.33, 38.45], last element of the list is the latest closing price. predict if the stock price next day will go up or down. your answer should either be up or down, do not elaborate.\", # here i could iteratively pass stock prices?\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "print(completion.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "print(prompt)\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"filler context\", \"question\": \"filler question\"}\n",
    ").to_messages()\n",
    "\n",
    "example_messages\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "for chunk in rag_chain.stream(\"When did Katharine Braddick join Barclays?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "response = rag_chain.invoke({\"input\": \"What is Task Decomposition?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Use three sentences maximum and keep the answer as concise as possible.\n",
    "Always say \"thanks for asking!\" at the end of the answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
