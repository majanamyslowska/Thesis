{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector DB with metadata filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prepare a list with keywords\n",
    "- for each keyword create a list of article links and the date, check if there's no overlap with the links\n",
    "- for each article generate a pdf with a name date+random\n",
    "- immediately pass through to the db, with the date as metadata\n",
    "- dont save the pdf to optimise space complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install psycopg2-binary pgvector asyncpg \"sqlalchemy[asyncio]\" greenlet\n",
    "# pip install llama-index-readers-file pymupdf\n",
    "# pip install llama-index-vector-stores-postgres\n",
    "# pip install llama-index-embeddings-huggingface\n",
    "# pip install llama-index-llms-llama-cpp\n",
    "# pip install llama-index-llms-openai\n",
    "\n",
    "# need keywords for energy sector, financials sector and consumer cyclical sector (for now)\n",
    "# i dont think i should add the names of ceos etc bc they woul dfor sure be mentioned with the company so its inefficient\n",
    "# energy: XOM, CVX, COP, EOG, SLB, Exxon, Chevron, ConocoPhillips, EOG Resources Inc, Schlumberger NV\n",
    "# oil, gas, energy, OPEC, power, electricity, green, utilities\n",
    "# financials: JPM, BAC, WFC, AXP, MS, JPMorgam, Bank of America, Wells Fargo, American Express, Morgan Stanley\n",
    "# bank, interest rates, savings, investment, regulation, inflation, employment, stock, bond, FED, SEC, NYSE, NASDAQ, S&P500\n",
    "\n",
    "# tech: MSFT, AAPL, NVDA, GOOGL, META, Microsoft, Apple, Nvidia, Alphabet, Meta\n",
    "# AI, Google, cybersecurity, fintech, data, cloud, \n",
    "\n",
    "\n",
    "# CC: AMZN, TSLA, HD, MCD, DIS, Amazon, Tesla, Home Depot, McDonald's, Disney\n",
    "# no for now\n",
    "\n",
    "# keywords = []\n",
    "\n",
    "keywords = [\n",
    "    # Energy Sector\n",
    "    \"XOM\", \"CVX\", \"COP\", \"EOG\", \"SLB\",\n",
    "    \"Exxon\", \"Chevron\", \"ConocoPhillips\", \"EOG Resources Inc\", \"Schlumberger NV\",\n",
    "    \"oil\", \"gas\", \"energy\", \"OPEC\", \"power\",\n",
    "    \"electricity\", \"green\", \"utilities\",\n",
    "\n",
    "    # Financials Sector\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"AXP\", \"MS\",\n",
    "    \"JPMorgan\", \"Bank of America\", \"Wells Fargo\", \"American Express\", \"Morgan Stanley\",\n",
    "    \"bank\", \"interest rates\", \"savings\", \"investment\", \"regulation\",\n",
    "    \"inflation\", \"employment\", \"stock\", \"bond\", \"FED\",\n",
    "    \"SEC\", \"NYSE\", \"NASDAQ\", \"S&P500\",\n",
    "\n",
    "    # Tech Sector\n",
    "    \"MSFT\", \"AAPL\", \"NVDA\", \"GOOGL\", \"META\",\n",
    "    \"Microsoft\", \"Apple\", \"Nvidia\", \"Alphabet\", \"Meta\",\n",
    "    \"AI\", \"Google\", \"cybersecurity\", \"fintech\", \"data\", \"cloud\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentence transformers setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Postgres setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_name = \"vector_db\"\n",
    "host = \"localhost\"\n",
    "password = \"password\"\n",
    "port = \"5432\"\n",
    "user = \"maja2\"\n",
    "conn = psycopg2.connect(\n",
    "    dbname=\"postgres\",\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "with conn.cursor() as c:\n",
    "    c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "    c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "vector_store = PGVectorStore.from_params(\n",
    "    database=db_name,\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    "    table_name=\"llama2_paper\",\n",
    "    embed_dim=384,\n",
    ")\n",
    "# # hybrid\n",
    "# url = make_url(conn)\n",
    "# hybrid_vector_store = PGVectorStore.from_params(\n",
    "#     database=db_name,\n",
    "#     host=url.host,\n",
    "#     password=url.password,\n",
    "#     port=url.port,\n",
    "#     user=url.username,\n",
    "#     table_name=\"paul_graham_essay_hybrid_search\",\n",
    "#     embed_dim=1536,  # openai embedding dimension\n",
    "#     hybrid_search=True,\n",
    "#     text_search_config=\"english\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingestion Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from llama_index.readers.file import PyMuPDFReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFReader()\n",
    "documents = loader.load(file_path=\"./data2/llama2.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a Text Splitter to Split Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_parser = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    # separator=\" \",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks = []\n",
    "doc_idxs = []\n",
    "for doc_idx, doc in enumerate(documents):\n",
    "    cur_text_chunks = text_parser.split_text(doc.text)\n",
    "    text_chunks.extend(cur_text_chunks)\n",
    "    doc_idxs.extend([doc_idx] * len(cur_text_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually Construct Nodes from Text Chunks / Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107\n",
      "Node ID: d757e0c0-966b-41d3-a325-eecfd08cc82e\n",
      "Text: Llama 2: Open Foundation and Fine-Tuned Chat Models Hugo\n",
      "Touvron∗ Louis Martin† Kevin Stone† Peter Albert Amjad Almahairi\n",
      "Yasmine Babaei Nikolay Bashlykov Soumya Batra Prajjwal Bhargava Shruti\n",
      "Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian\n",
      "Fuller Cynthia Gao...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "\n",
    "nodes = []\n",
    "for idx, text_chunk in enumerate(text_chunks):\n",
    "    node = TextNode(\n",
    "        text=text_chunk,\n",
    "    )\n",
    "    src_doc = documents[doc_idxs[idx]]\n",
    "    node.metadata = src_doc.metadata\n",
    "    nodes.append(node)\n",
    "    \n",
    "print(len(nodes))\n",
    "print(nodes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings for each Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_embedding = embed_model.get_text_embedding(\n",
    "        node.get_content(metadata_mode=\"all\")\n",
    "    )\n",
    "    node.embedding = node_embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Llama 2: Open Foundation and Fine-Tuned Chat Models\n",
      "Hugo Touvron∗\n",
      "Louis Martin†\n",
      "Kevin Stone†\n",
      "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
      "Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\n",
      "Guillem Cucurull David Esiobu Jude Fernandes Jeremy Fu Wenyin Fu Brian Fuller\n",
      "Cynthia Gao Vedanuj Goswami Naman Goyal Anthony Hartshorn Saghar Hosseini Rui Hou\n",
      "Hakan Inan Marcin Kardas Viktor Kerkez Madian Khabsa Isabel Kloumann Artem Korenev\n",
      "Punit Singh Koura Marie-Anne Lachaux Thibaut Lavril Jenya Lee Diana Liskovich\n",
      "Yinghai Lu Yuning Mao Xavier Martinet Todor Mihaylov Pushkar Mishra\n",
      "Igor Molybog Yixin Nie Andrew Poulton Jeremy Reizenstein Rashi Rungta Kalyan Saladi\n",
      "Alan Schelten Ruan Silva Eric Michael Smith Ranjan Subramanian Xiaoqing Ellen Tan Binh Tang\n",
      "Ross Taylor Adina Williams Jian Xiang Kuan Puxin Xu Zheng Yan Iliyan Zarov Yuchen Zhang\n",
      "Angela Fan Melanie Kambadur Sharan Narang Aurelien Rodriguez Robert Stojnic\n",
      "Sergey Edunov\n",
      "Thomas Scialom∗\n",
      "GenAI, Meta\n",
      "Abstract\n",
      "In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned\n",
      "large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters.\n",
      "Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our\n",
      "models outperform open-source chat models on most benchmarks we tested, and based on\n",
      "our human evaluations for helpfulness and safety, may be a suitable substitute for closed-\n",
      "source models. We provide a detailed description of our approach to fine-tuning and safety\n",
      "improvements of Llama 2-Chat in order to enable the community to build on our work and\n",
      "contribute to the responsible development of LLMs.\n",
      "∗Equal contribution, corresponding authors: {tscialom, htouvron}@meta.com\n",
      "†Second author\n",
      "Contributions for all the authors can be found in Section A.1.\n",
      "arXiv:2307.09288v2  [cs.CL]  19 Jul 2023\n",
      "Metadata: {'total_pages': 77, 'file_path': './data2/llama2.pdf', 'source': '1'}\n",
      "Embedding: [-0.045876991003751755, 0.03385550156235695, -0.014578117057681084, -0.007513393182307482, 0.013720102608203888, 0.0004939759965054691, -0.006911910604685545, 0.015459852293133736, 0.025924870744347572, -0.0077187977731227875, -0.012053211219608784, -0.04009491205215454, 0.06261619925498962, 0.01961120031774044, 0.05538030341267586, 0.03713593631982803, 0.017757074907422066, -0.014758288860321045, 0.0058096954599022865, 0.033305149525403976, -0.012216388247907162, -0.04394088685512543, 0.013167271390557289, 0.0065295095555484295, -0.024255899712443352, 0.0214045662432909, -0.037307433784008026, -0.034547753632068634, -0.006296951789408922, -0.22229738533496857, -0.004495937842875719, 0.005183355417102575, 0.04892349615693092, 0.008581957779824734, -0.05742884799838066, -0.009946131147444248, -0.002393940929323435, -0.022458381950855255, -0.025807563215494156, 0.01782483421266079, 0.006162611767649651, 0.003333493834361434, 0.017279986292123795, -0.02251293882727623, -0.016572555527091026, -0.06867942214012146, -0.050364572554826736, 0.01232551597058773, -0.06612125039100647, -0.014956542290747166, 0.010913114994764328, -0.034593500196933746, 0.011031812988221645, 0.02727329172194004, 0.012945049442350864, 0.00048258580500259995, 0.02304762415587902, 0.03116186521947384, -0.018460258841514587, 0.025212105363607407, -0.0005198565777391195, 0.008070513606071472, -0.19829502701759338, 0.02242407388985157, -0.02602977305650711, 0.028929641470313072, -0.025676481425762177, -0.007183814886957407, 0.022186486050486565, 0.017634540796279907, 0.006653520278632641, 0.002903577173128724, 0.02477429062128067, -0.015013514086604118, 0.04034537822008133, 0.025341834872961044, 0.000703660596627742, -0.01618112064898014, 0.05123985558748245, 0.025747790932655334, 0.014051249250769615, -0.03127732500433922, 0.015062198974192142, -0.016884204000234604, -0.015114355832338333, -0.028014209121465683, 0.011915060691535473, -0.011310495436191559, -0.040497779846191406, 0.003808192675933242, -0.006335430778563023, -0.0010635823709890246, 0.06494279950857162, 0.03794293478131294, -0.08012446761131287, -0.0180814191699028, -0.00028104649391025305, 0.00917001161724329, -0.05464908853173256, 0.6236746311187744, 0.009708543308079243, 0.018476560711860657, 0.004796410445123911, -0.0379355363547802, 0.015182343311607838, -0.01196981780230999, -0.0003632849839050323, -0.0445459820330143, -0.002584888134151697, 0.011574926786124706, -0.021645238623023033, -0.0024941887240856886, 0.05747494101524353, -0.008520527742803097, -0.00459666084498167, 0.05124108865857124, 0.06054285168647766, 0.017182854935526848, -0.0070777349174022675, -0.00906429998576641, -0.022735467180609703, 0.01615110971033573, 0.00363432546146214, -0.058754175901412964, 0.019600849598646164, -0.07542143762111664, 0.03405075892806053, 0.05273902043700218, 0.036785662174224854, 0.026643123477697372, 0.04081845283508301, -0.0029010018333792686, -0.040145810693502426, 0.006817791145294905, 0.05735842511057854, -0.004857075400650501, 0.008326058275997639, -0.02107970416545868, 0.006277775391936302, 0.0016153353499248624, 0.01827280968427658, -0.07112737745046616, 0.0038719908334314823, -0.06407400965690613, -0.05142964422702789, 0.07818955928087234, 0.008899292908608913, -0.013527687638998032, -0.04562590271234512, 0.02135287970304489, 0.0288864616304636, 0.045681435614824295, -0.0016349951038137078, 0.005133943632245064, 0.04908479377627373, 0.008294443599879742, 0.03861597180366516, 0.021008050069212914, -0.04450470209121704, 0.010290142148733139, 0.026179922744631767, -0.03649351745843887, -0.030033769086003304, 0.07163293659687042, -0.016452768817543983, -0.08784361183643341, -0.042290981858968735, -0.004299817606806755, 0.020691046491265297, -0.05275067687034607, 0.07374835014343262, 0.021114684641361237, -0.007794697768986225, 0.008284986019134521, -0.003949879668653011, 0.009797505103051662, -0.06862973421812057, 0.005720976740121841, -0.0003978376917075366, 0.031575657427310944, 0.016558634117245674, 0.0018864835146814585, -0.036390356719493866, 0.008903846144676208, -0.03695362061262131, -0.05585196986794472, -0.0018937301356345415, -0.02303262986242771, 0.03348530828952789, -0.026348115876317024, -0.04245545715093613, 0.04054645076394081, -0.025816524401307106, 0.0295438040047884, -0.012053115293383598, -0.01145605556666851, -0.04033162444829941, -0.003840111894533038, -0.025770898908376694, -0.032683540135622025, -0.002210871549323201, 0.027325110509991646, -0.050460588186979294, -0.009921868331730366, -0.03828819841146469, -0.012883596122264862, 0.015488509088754654, 0.008313998579978943, 0.035265274345874786, 0.037516120821237564, -0.04108088091015816, 0.029133886098861694, 0.009313124231994152, 0.0017958071548491716, 0.0034903965424746275, 0.009935403242707253, 0.036418616771698, 0.03276664763689041, 0.02116851881146431, 0.043009545654058456, 0.01105218194425106, -0.004358009900897741, -0.05685222148895264, -0.2428186684846878, -0.02470341883599758, -0.012743956409394741, -0.004480513744056225, -0.006954427808523178, -0.04918089881539345, 0.013509083539247513, -0.02489553391933441, 0.03607102483510971, 0.06311018019914627, 0.05075591430068016, 0.01972767524421215, -0.05540028214454651, 0.024398677051067352, -0.009977299720048904, 0.006941371131688356, -0.019300278276205063, 0.025159569457173347, -0.011861815117299557, 0.027759483084082603, -0.00207397248595953, 0.05067684128880501, -0.00042528018821030855, -0.06447061151266098, 0.031100768595933914, 0.009969648905098438, 0.12199821323156357, 0.04244673624634743, -0.013200817629694939, -0.046728622168302536, 0.029172467067837715, 0.0286038089543581, -0.018788224086165428, -0.10417415201663971, 0.06299210339784622, -0.0008718024473637342, 0.03455924242734909, -0.02388887107372284, -0.008733090944588184, 0.003772435477003455, -0.01202732790261507, -0.0035455652978271246, -0.01580502651631832, -0.05188656970858574, -0.04181699827313423, -0.007862571626901627, -0.007562051061540842, -0.05292268842458725, -0.04369809851050377, -0.022004328668117523, -0.01388073991984129, 0.018344614654779434, 0.05260639265179634, 0.018547577783465385, -0.07221367955207825, 0.0067062960006296635, -0.0762881338596344, -0.003092436119914055, -0.03304293751716614, -0.01728750392794609, -0.05279871076345444, -0.011419836431741714, -0.03623972460627556, -0.030720612034201622, 0.023361267521977425, -0.0022098184563219547, 0.017327168956398964, 0.0032315319404006004, 0.004097461700439453, -0.04603707045316696, 0.020995480939745903, 0.09837166965007782, -0.03238866850733757, 0.006738456431776285, 0.015491374768316746, -0.015476202592253685, 0.02809198759496212, -0.024140335619449615, -0.041233766824007034, -0.020269636064767838, 0.054965995252132416, 0.011182158254086971, 0.0412679985165596, 0.01924983412027359, 0.0015159141039475799, -0.007003405597060919, 0.04549161717295647, 0.01386296283453703, 0.025538086891174316, 0.0032542140688747168, -0.04538073390722275, -0.020687146112322807, 0.0011539916740730405, -0.019034355878829956, 0.0034274819772690535, 0.01738555356860161, -0.2514439523220062, -0.03230087831616402, 0.00497219106182456, 0.015007242560386658, -0.018244845792651176, 0.01993846893310547, 0.02664213627576828, -0.011354072019457817, -0.00756622152402997, 0.03242345526814461, 0.01538811530917883, 0.06285201013088226, 0.04933585599064827, 0.01924910768866539, 0.01543043926358223, -0.0236137043684721, 0.03605762869119644, -0.013502112589776516, 0.0008222906035371125, 0.018560314550995827, 0.004786960780620575, -0.01134338416159153, 0.1471332609653473, -0.01963104121387005, 0.024608071893453598, 0.0009717172360979021, 0.0046403673477470875, 0.008961500599980354, -0.00039432544144801795, 0.004169070161879063, 0.019819913432002068, 0.011165343225002289, 0.07907240092754364, -0.02251576818525791, 0.00036684839869849384, 0.012434689328074455, -0.03817310184240341, 0.05079742893576622, 0.018790194764733315, -1.1106274541816674e-05, -0.02623487263917923, 0.014804716221988201, 0.012824024073779583, -0.00021620783081743866, 0.02938002720475197, 0.013238801620900631, -0.03807338699698448, -0.016706416383385658, 0.00861883070319891, 0.046152252703905106, -0.0015014319214969873, -0.024693524464964867, -0.01669171266257763, 0.019645676016807556, 0.020967362448573112, 0.0055799325928092, 0.004671086091548204, 0.0067569357343018055, 0.007374207489192486, -0.01721491478383541, 0.004386398009955883, -0.02736777253448963, -0.0003807245520874858, 0.02221410721540451, 0.034102704375982285]\n"
     ]
    }
   ],
   "source": [
    "node = nodes[0]\n",
    "print(\"Text:\", node.text)\n",
    "print(\"Metadata:\", node.metadata)\n",
    "print(\"Embedding:\", getattr(node, 'embedding', 'No embedding found'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Nodes into a Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['422406ad-f62c-49da-bf3b-c9ac7740d3fc',\n",
       " 'bf46ed30-c6f2-4a96-a561-6d6a35870306',\n",
       " '4ec4d802-3658-4140-99e0-c5505ecb5196',\n",
       " '7c0934dc-f564-4630-8b2c-44e50dac9267',\n",
       " '7bea4802-4717-4e35-b919-840ce03fafed',\n",
       " '0815dee1-fd30-4d0e-a4ac-8af98a3a3f96',\n",
       " '240b44ff-0f64-4e15-84ad-b9757d98ca20',\n",
       " '243d9fc4-6afa-430e-8c7a-5ac14b419647',\n",
       " '1f2215a3-db8f-4bea-b784-36bf92a3fcb9',\n",
       " 'd8f24aee-9876-4dd1-911a-8fce33eeb453',\n",
       " '3c04dd71-b449-4ba3-8874-6b3365195078',\n",
       " '7f5eae28-949a-404b-8ee7-3bf2d12dee29',\n",
       " '09c2a011-890e-4871-b6f2-fb4081d0f661',\n",
       " '26d85b6c-9ef3-4dcc-af7b-b5d9ae01cab1',\n",
       " 'f852c12e-3606-4fbd-a8c2-067e7327d35d',\n",
       " '00242be6-5c1e-4d36-bda4-88340aaf852a',\n",
       " '3ccd93c8-ef20-413a-855f-efae7bd280fa',\n",
       " 'abaa9e09-064e-4647-8048-25d681e8036e',\n",
       " '4661625f-28ec-4db6-b665-c4e89bd4250f',\n",
       " 'e7b53c06-6c2e-472f-9db3-7b7b2672003e',\n",
       " '7d71b4e2-8f4f-4123-ab96-67532d0d9380',\n",
       " '2fd3eb09-6a51-47a2-89fe-b08c7bec8bb7',\n",
       " 'a5c9e867-5c58-4e2f-bc9a-0197b298df15',\n",
       " 'd3e219d7-c612-45b9-8d5a-c8d967265948',\n",
       " '55147c50-35e4-4f61-9607-fd3c5c30f471',\n",
       " '933fa766-1d26-4662-9a8e-da0cfa991f94',\n",
       " 'fc77fc69-7ed3-46e8-a208-2fdede339137',\n",
       " '862af796-4e0f-4a03-852d-8cfc24e794e0',\n",
       " '352155df-c478-45df-ae4e-b0964aac371d',\n",
       " 'b1dba564-d47e-4ac2-9a1a-85094f57e443',\n",
       " '78c46d3a-ed9b-4bc0-996f-39cfea91b127',\n",
       " '8749c636-b70b-4ffd-bf4b-5e7c3dc1bab5',\n",
       " '125b1bbe-02ac-4c66-ba94-e482cda0c7e4',\n",
       " 'dcda3c32-53a1-478e-bf5f-3a0afa99d963',\n",
       " 'be6a1a64-d6c9-4f9b-9948-0b708e17de9a',\n",
       " 'ab77afd8-d251-4ed7-8c00-1efe2ecd419d',\n",
       " 'eb6f1d9f-1c6d-4956-af2e-7ef9cc9e60d6',\n",
       " '4d1e241e-af54-4da4-846a-63b7ad672b34',\n",
       " '8577bf64-fafd-409e-b826-43e8689a5f8c',\n",
       " '51b98cc5-714f-40e9-9841-30a5b19f573d',\n",
       " '74b3604c-e739-453d-a9dc-b8c9d959681b',\n",
       " '33653a9d-ba79-4e16-ae81-8ea28524c448',\n",
       " '7e3e8119-4bde-4c4a-b1a3-61dea8340c8e',\n",
       " '5d65c1e9-c32a-4b77-b473-00f591305c0b',\n",
       " 'c68a597d-07e9-4f82-bf8a-07c29e87200b',\n",
       " 'e5ba7157-c7a0-4e65-9b70-f5f50d2289a2',\n",
       " 'f22f58c2-ca16-4054-a9bc-447f0ff43319',\n",
       " '5a32042d-fb71-4fdb-8296-2fb5b1d6076d',\n",
       " '11b04467-8feb-48ed-be80-e90fc4bb085e',\n",
       " 'fcc91f43-20e7-486e-84c2-862af16cf80c',\n",
       " '485d6efd-f613-40d6-a04b-9cbe9d226e98',\n",
       " 'a7519fef-537f-447e-83d9-258f0e4e4ccd',\n",
       " '9dac53cd-4a06-4bc2-8d48-89ec119e3301',\n",
       " '56b07d57-45a5-4a83-b2f0-ae096d1bc81e',\n",
       " '10c2f537-d9d7-466c-93ca-032c12d479cf',\n",
       " '93e42860-ba00-41b8-8b59-36198c3cce45',\n",
       " '37203ceb-c7e7-4eb9-b2a9-a056b9f83857',\n",
       " '4d60e40d-8afa-4141-941b-a44192948a6b',\n",
       " 'e1c692be-fb63-43a4-83b9-b67da03d09da',\n",
       " '5516a4dc-48c4-4140-9957-d49345e87c80',\n",
       " 'dfc7695d-c7e3-49a8-8669-e0d4fd22b7f6',\n",
       " '1ec5cf6c-8589-4c5f-b01f-4a3cec113fcb',\n",
       " '05307646-7a27-4b5f-b1cc-0d91bf06191e',\n",
       " '804a2c2c-fbf2-45c7-91d1-51a46825c0d6',\n",
       " 'e9f28152-381b-462c-9c30-21ee99adabf5',\n",
       " '5b14a1a9-0154-49c0-b801-a3967b7e5654',\n",
       " 'f3198b25-92e1-4d46-bb78-df2835ff0f5e',\n",
       " 'cd0afbd5-9266-4aa9-8ef9-0ad5705c4a75',\n",
       " 'eb0f78d9-0ab3-445b-943f-87f813b557d2',\n",
       " '6dd46a6f-df61-4420-b4a0-f30531879f21',\n",
       " '3c5dfc61-6592-49ba-bf73-bb7e69e4bc47',\n",
       " '6dc840f9-7ae1-4709-9553-8504fea5ad59',\n",
       " 'fd057b1c-660c-4af4-818f-53f2c8baff81',\n",
       " 'fbf0b86d-1c09-40ad-a277-790b1ca28087',\n",
       " 'd2c5ec64-5b7c-4942-861f-143e2bd50d06',\n",
       " '6706eec7-e7a5-489b-b0bf-0983e4d28a27',\n",
       " '3c6d0b44-abee-487f-9403-d43f61bc601e',\n",
       " 'dcb4ec7b-e8e4-4efb-ab80-83db3f8556be',\n",
       " 'e236e452-9916-4bf8-9d0e-2c132dfeb010',\n",
       " 'cd9e5684-0e55-4afe-9c87-6a1095a5c8d0',\n",
       " 'aa3e1a1e-b52f-4420-84c5-2933b27de9e8',\n",
       " '9b72a8dc-e3fe-4e0c-bbb7-126af104b40f',\n",
       " 'e5b6f2a4-8f78-4013-933f-a68246f3b3e1',\n",
       " '079468e3-9926-462c-871f-6320892505a6',\n",
       " '9718e2fc-8fd6-4eb0-8067-d4ac3f4a94f9',\n",
       " '73dcbe47-c6b2-47e1-8745-75c1993d380b',\n",
       " '649addef-9e44-45c3-a379-63ef991da0a1',\n",
       " 'd15d1789-fedd-4e03-87d9-e6fce1e4f05f',\n",
       " '2bbf6d0c-c8fb-4db5-9b8c-94a30b07b8cd',\n",
       " '9ccdb581-3ff7-4d07-b051-237fcad95b2e',\n",
       " 'dec6fe62-5d8a-422e-af76-8bf33a31ad7a',\n",
       " '781f7af4-7f0f-4bcb-b9fb-5a04173b0dfa',\n",
       " 'bb2645b9-0677-4ed1-a4d7-497189458ea4',\n",
       " 'da323576-1a2e-4a70-b0ae-eeaa059e8051',\n",
       " 'cd7cb141-2426-495f-9f46-3e731717b879',\n",
       " '77bb6a8e-e00f-4903-88ed-20c65c660c95',\n",
       " '569fa5d3-4749-4859-91e7-b18d0a171c6e',\n",
       " 'c69a39c9-9544-46c3-bfd4-4b6c61d423c8',\n",
       " '8685636d-34e6-4aea-a46f-1a1e933be8b2',\n",
       " '7e913597-bb47-48ff-bed5-da123942351e',\n",
       " '1927ea79-fc05-4bd0-ae26-7009b856fea3',\n",
       " 'e6484b23-d7d2-43e7-84ee-bcecd478e7fd',\n",
       " 'e62208d8-6124-4119-9966-73bf0f99acf0',\n",
       " 'ac55a8cd-3eeb-4f8e-8a89-62289d06b257',\n",
       " '7848b4a7-2b5b-4b0c-ba8e-6d3987a3e46c',\n",
       " 'fcd74498-c9e4-43f0-8a47-a3d0b6441509',\n",
       " '05412760-fbc1-4553-a1b5-d0a03d075397']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_str = \"Can you tell me about the key concepts for safety finetuning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a Query Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_embedding = embed_model.get_query_embedding(query_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.vector_stores import VectorStoreQuery\n",
    "\n",
    "query_mode = \"default\"\n",
    "\n",
    "\n",
    "vector_store_query = VectorStoreQuery(\n",
    "    query_embedding=query_embedding, similarity_top_k=2, mode=query_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TruthfulQA ↑\n",
      "ToxiGen ↓\n",
      "MPT\n",
      "7B\n",
      "29.13\n",
      "22.32\n",
      "30B\n",
      "35.25\n",
      "22.61\n",
      "Falcon\n",
      "7B\n",
      "25.95\n",
      "14.53\n",
      "40B\n",
      "40.39\n",
      "23.44\n",
      "Llama 1\n",
      "7B\n",
      "27.42\n",
      "23.00\n",
      "13B\n",
      "41.74\n",
      "23.08\n",
      "33B\n",
      "44.19\n",
      "22.57\n",
      "65B\n",
      "48.71\n",
      "21.77\n",
      "Llama 2\n",
      "7B\n",
      "33.29\n",
      "21.25\n",
      "13B\n",
      "41.86\n",
      "26.10\n",
      "34B\n",
      "43.45\n",
      "21.19\n",
      "70B\n",
      "50.18\n",
      "24.60\n",
      "Table 11: Evaluation of pretrained LLMs on automatic safety benchmarks. For TruthfulQA, we present the\n",
      "percentage of generations that are both truthful and informative (the higher the better). For ToxiGen, we\n",
      "present the percentage of toxic generations (the smaller, the better).\n",
      "Benchmarks give a summary view of model capabilities and behaviors that allow us to understand general\n",
      "patterns in the model, but they do not provide a fully comprehensive view of the impact the model may have\n",
      "on people or real-world outcomes; that would require study of end-to-end product deployments. Further\n",
      "testing and mitigation should be done to understand bias and other social issues for the specific context\n",
      "in which a system may be deployed. For this, it may be necessary to test beyond the groups available in\n",
      "the BOLD dataset (race, religion, and gender). As LLMs are integrated and deployed, we look forward to\n",
      "continuing research that will amplify their potential for positive impact on these important social issues.\n",
      "4.2\n",
      "Safety Fine-Tuning\n",
      "In this section, we describe our approach to safety fine-tuning, including safety categories, annotation\n",
      "guidelines, and the techniques we use to mitigate safety risks. We employ a process similar to the general\n",
      "fine-tuning methods as described in Section 3, with some notable differences related to safety concerns.\n",
      "Specifically, we use the following techniques in safety fine-tuning:\n",
      "1. Supervised Safety Fine-Tuning: We initialize by gathering adversarial prompts and safe demonstra-\n",
      "tions that are then included in the general supervised fine-tuning process (Section 3.1). This teaches\n",
      "the model to align with our safety guidelines even before RLHF, and thus lays the foundation for\n",
      "high-quality human preference data annotation.\n",
      "2. Safety RLHF: Subsequently, we integrate safety in the general RLHF pipeline described in Sec-\n",
      "tion 3.2.2. This includes training a safety-specific reward model and gathering more challenging\n",
      "adversarial prompts for rejection sampling style fine-tuning and PPO optimization.\n",
      "3. Safety Context Distillation: Finally, we refine our RLHF pipeline with context distillation (Askell\n",
      "et al., 2021b). This involves generating safer model responses by prefixing a prompt with a safety\n",
      "preprompt, e.g., “You are a safe and responsible assistant,” and then fine-tuning the model on the safer\n",
      "responses without the preprompt, which essentially distills the safety preprompt (context) into the\n",
      "model. We use a targeted approach that allows our safety reward model to choose whether to use\n",
      "context distillation for each sample.\n",
      "4.2.1\n",
      "Safety Categories and Annotation Guidelines\n",
      "Based on limitations of LLMs known from prior work, we design instructions for our annotation team to\n",
      "create adversarial prompts along two dimensions: a risk category, or potential topic about which the LLM\n",
      "could produce unsafe content; and an attack vector, or question style to cover different varieties of prompts\n",
      "that could elicit bad model behaviors.\n",
      "The risk categories considered can be broadly divided into the following three categories: illicit and criminal\n",
      "activities (e.g., terrorism, theft, human trafficking); hateful and harmful activities (e.g., defamation, self-\n",
      "harm, eating disorders, discrimination); and unqualified advice (e.g., medical advice, financial advice, legal\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "query_result = vector_store.query(vector_store_query)\n",
    "print(query_result.nodes[0].get_content())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse Result into a Set of Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import NodeWithScore\n",
    "from typing import Optional\n",
    "\n",
    "nodes_with_scores = []\n",
    "for index, node in enumerate(query_result.nodes):\n",
    "    score: Optional[float] = None\n",
    "    if query_result.similarities is not None:\n",
    "        score = query_result.similarities[index]\n",
    "    nodes_with_scores.append(NodeWithScore(node=node, score=score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put into a Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from typing import Any, List\n",
    "\n",
    "\n",
    "class VectorDBRetriever(BaseRetriever):\n",
    "    \"\"\"Retriever over a postgres vector store.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        vector_store: PGVectorStore,\n",
    "        embed_model: Any,\n",
    "        query_mode: str = \"default\",\n",
    "        similarity_top_k: int = 2,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self._vector_store = vector_store\n",
    "        self._embed_model = embed_model\n",
    "        self._query_mode = query_mode\n",
    "        self._similarity_top_k = similarity_top_k\n",
    "        super().__init__()\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve.\"\"\"\n",
    "        query_embedding = embed_model.get_query_embedding(\n",
    "            query_bundle.query_str\n",
    "        )\n",
    "        vector_store_query = VectorStoreQuery(\n",
    "            query_embedding=query_embedding,\n",
    "            similarity_top_k=self._similarity_top_k,\n",
    "            mode=self._query_mode,\n",
    "        )\n",
    "        query_result = vector_store.query(vector_store_query)\n",
    "\n",
    "        nodes_with_scores = []\n",
    "        for index, node in enumerate(query_result.nodes):\n",
    "            score: Optional[float] = None\n",
    "            if query_result.similarities is not None:\n",
    "                score = query_result.similarities[index]\n",
    "            nodes_with_scores.append(NodeWithScore(node=node, score=score))\n",
    "\n",
    "        return nodes_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorDBRetriever(\n",
    "    vector_store, embed_model, query_mode=\"default\", similarity_top_k=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetrieverQueryEngine Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The temperature parameter plays a crucial role in the exploration process during the RLHF training. It influences the diversity of the outputs generated by the model. A higher temperature allows for more varied responses, which can lead to better exploration of the output space. The optimal temperature is not static and changes during iterative model updates, indicating that RLHF affects how temperature is adjusted. Specifically, for the Llama 2-Chat-RLHF model, the optimal temperature when sampling between 10 and 100 outputs ranges from approximately 1.2 to 1.3. This necessitates a progressive re-adjustment of the temperature within a finite compute budget to maximize performance.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "query_engine = RetrieverQueryEngine.from_args(retriever, llm=llm)\n",
    "\n",
    "query_str = \"Describe the RLHF impact of the temperature\"\n",
    "response = query_engine.query(query_str)\n",
    "\n",
    "print(str(response))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additionally, Llama 2 70B model outperforms all open-source models.\n",
      "In addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\n",
      "in Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\n",
      "gap on coding benchmarks. Llama 2 70B results are on par or better than PaLM (540B) (Chowdhery et al.,\n",
      "2022) on almost all benchmarks. There is still a large gap in performance between Llama 2 70B and GPT-4\n",
      "and PaLM-2-L.\n",
      "We also analysed the potential data contamination and share the details in Section A.6.\n",
      "Benchmark (shots)\n",
      "GPT-3.5\n",
      "GPT-4\n",
      "PaLM\n",
      "PaLM-2-L\n",
      "Llama 2\n",
      "MMLU (5-shot)\n",
      "70.0\n",
      "86.4\n",
      "69.3\n",
      "78.3\n",
      "68.9\n",
      "TriviaQA (1-shot)\n",
      "–\n",
      "–\n",
      "81.4\n",
      "86.1\n",
      "85.0\n",
      "Natural Questions (1-shot)\n",
      "–\n",
      "–\n",
      "29.3\n",
      "37.5\n",
      "33.0\n",
      "GSM8K (8-shot)\n",
      "57.1\n",
      "92.0\n",
      "56.5\n",
      "80.7\n",
      "56.8\n",
      "HumanEval (0-shot)\n",
      "48.1\n",
      "67.0\n",
      "26.2\n",
      "–\n",
      "29.9\n",
      "BIG-Bench Hard (3-shot)\n",
      "–\n",
      "–\n",
      "52.3\n",
      "65.7\n",
      "51.2\n",
      "Table 4: Comparison to closed-source models on academic benchmarks. Results for GPT-3.5 and GPT-4\n",
      "are from OpenAI (2023). Results for the PaLM model are from Chowdhery et al. (2022). Results for the\n",
      "PaLM-2-L are from Anil et al. (2023).\n",
      "3\n",
      "Fine-tuning\n",
      "Llama 2-Chat is the result of several months of research and iterative applications of alignment techniques,\n",
      "including both instruction tuning and RLHF, requiring significant computational and annotation resources.\n",
      "In this section, we report on our experiments and findings using supervised fine-tuning (Section 3.1), as\n",
      "well as initial and iterative reward modeling (Section 3.2.2) and RLHF (Section 3.2.3). We also share a\n",
      "new technique, Ghost Attention (GAtt), which we find helps control dialogue flow over multiple turns\n",
      "(Section 3.3). See Section 4.2 for safety evaluations on fine-tuned models.\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(response.source_nodes[0].get_content())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
