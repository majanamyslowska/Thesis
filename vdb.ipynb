{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE A VECTOR DB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a list of articles (link, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [\n",
    "    # Energy Sector\n",
    "    \"XOM\", \"CVX\", \"COP\", \"EOG\", \"SLB\",\n",
    "    \"Exxon\", \"Chevron\", \"ConocoPhillips\", \"EOG Resources Inc\", \"Schlumberger NV\",\n",
    "    \"oil\", \"gas\", \"energy\", \"OPEC\", \"power\",\n",
    "    \"electricity\", \"green\", \"utilities\",\n",
    "\n",
    "    # Financials Sector\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"AXP\", \"MS\",\n",
    "    \"JPMorgan\", \"Bank of America\", \"Wells Fargo\", \"American Express\", \"Morgan Stanley\",\n",
    "    \"bank\", \"interest rates\", \"savings\", \"investment\", \"regulation\",\n",
    "    \"inflation\", \"employment\", \"stock\", \"bond\", \"FED\",\n",
    "    \"SEC\", \"NYSE\", \"NASDAQ\", \"S&P500\",\n",
    "\n",
    "    # Tech Sector\n",
    "    \"MSFT\", \"AAPL\", \"NVDA\", \"GOOGL\", \"META\",\n",
    "    \"Microsoft\", \"Apple\", \"Nvidia\", \"Alphabet\", \"Meta\",\n",
    "    \"AI\", \"Google\", \"cybersecurity\", \"fintech\", \"data\", \"cloud\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Status Code: 200\n",
      "2\n",
      "Total articles collected in news_data: 7\n",
      "[['Is ChatGPT good at day trading? Probably not', '/content/0608b6a0-f586-430c-9e68-a177c544435a', 'March 28, 2024'], ['GraniteShares files to increase leverage on 17 ETFs', '/content/f26c4b3b-baa4-4586-9fa2-bf8d63fd457b', 'November 30, 2023'], ['Microsoft, and a macro lesson', '/content/d5ba4cab-7976-4352-b624-7654c6acf7c3', 'October 28, 2021'], ['High expectations leave no room for errorPremiumcontent', '/content/ed5c04dd-75cf-4338-b51c-869affebedde', 'July 7, 2020'], ['Markets not live, Thursday 30th January 2020', '/content/ad45f2d9-07e6-4b0c-a040-f831f8af5ae8', 'January 30, 2020'], ['Chinaâ€™s credit pulse has a kickPremiumcontent', '/content/3c35f688-36f6-11ea-a6d3-9a26f8c3cba4', 'January 14, 2020'], ['Investors Chronicle: Tesco, Serco, Apple', '/content/6fbc606c-1359-11e9-a581-4ff78404524e', 'January 11, 2019']]\n"
     ]
    }
   ],
   "source": [
    "# ft articles data [heading, link, date] for a hardcoded keyword\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "news_data = []\n",
    "keyword = 'aapl'\n",
    "cutoff_date = datetime.strptime(\"01-Dec-2018\", \"%d-%b-%Y\")\n",
    "\n",
    "keyurl = f\"https://www.ft.com/search?q={keyword}&page=1&sort=date&isFirstView=true\"\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.ft.com/',\n",
    "    'Origin': 'https://www.ft.com'\n",
    "}\n",
    "\n",
    "keyresult = requests.get(keyurl, headers=headers)\n",
    "# keyresult = requests.get(keyurl)\n",
    "print(f\"HTTP Status Code: {keyresult.status_code}\")\n",
    "\n",
    "keyresult_content = keyresult.content\n",
    "keysoup = BeautifulSoup(keyresult_content, \"html.parser\")\n",
    "# print(keysoup.prettify())\n",
    "maxpages = keysoup.find('span', {\"class\": \"search-pagination__page\"})\n",
    "maxpages = int(maxpages.get_text(strip=True).split()[-1])\n",
    "# maxpages += 5\n",
    "print(maxpages)\n",
    "\n",
    "\n",
    "for page in range(1, maxpages):\n",
    "    url = f\"https://www.ft.com/search?q={keyword}&page={page}&sort=date&isFirstView=true\"\n",
    "    result = requests.get(url, headers=headers)\n",
    "    # print(page)\n",
    "    # print(result.text)\n",
    "    if \"Sorry\" in result.text: # maybe unnecessary\n",
    "        print(f\"Stopping iteration: Page {page} is not available.\")\n",
    "        break\n",
    "    \n",
    "    result_content = result.content\n",
    "    soup = BeautifulSoup(result_content, \"lxml\")\n",
    "    \n",
    "    for article in soup.findAll(\"div\", {\"class\": \"o-teaser\"}):\n",
    "        heading = article.find(\"div\", {\"class\": \"o-teaser__heading\"}).get_text(strip=True) #find(text=True), find text is outdated\n",
    "        link = article.find(\"div\", {\"class\": \"o-teaser__heading\"}).find('a', href=True)\n",
    "        date = article.find('time', {\"class\": \"o-teaser__timestamp-date\"})\n",
    "        \n",
    "        # print(heading, link, date)\n",
    "        if heading and link and date:\n",
    "            article_date = datetime.strptime(date.text.strip(), \"%B %d, %Y\")\n",
    "            if article_date > cutoff_date:\n",
    "                news_data.append([heading, link['href'], date.text.strip()])\n",
    "\n",
    "# print(pages)\n",
    "\n",
    "print(f\"Total articles collected in news_data: {len(news_data)}\")\n",
    "# print(news_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping keyword 'Chevron' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'ConocoPhillips' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'EOG Resources Inc' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Schlumberger NV' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'oil' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'gas' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'energy' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'OPEC' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'power' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'electricity' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'green' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'utilities' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'JPM' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'BAC' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'WFC' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'AXP' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'MS' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'JPMorgan' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Bank of America' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Wells Fargo' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'American Express' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Morgan Stanley' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'bank' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'interest rates' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'savings' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'investment' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'regulation' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'inflation' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'employment' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'stock' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'bond' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'FED' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'SEC' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'NYSE' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'NASDAQ' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'S&P500' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'MSFT' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'AAPL' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'NVDA' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'GOOGL' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'META' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Microsoft' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Apple' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Nvidia' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Alphabet' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Meta' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'AI' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'Google' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'cybersecurity' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'fintech' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'data' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Skipping keyword 'cloud' due to error: 'NoneType' object has no attribute 'get_text'\n",
      "Total articles collected in news_data: 593\n"
     ]
    }
   ],
   "source": [
    "# ft articles data [heading, link, date] for a list of keywords, need to split the keywords list bc it crashes\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "news_data = []\n",
    "collected_links = set()\n",
    "cutoff_date = datetime.strptime(\"01-Dec-2018\", \"%d-%b-%Y\")\n",
    "\n",
    "keywords = [\n",
    "    # Energy Sector\n",
    "    \"XOM\", \"CVX\", \"EOG\", \"SLB\",\n",
    "    \"Exxon\", \"Chevron\", \"ConocoPhillips\", \"EOG Resources Inc\", \"Schlumberger NV\",\n",
    "    \"oil\", \"gas\", \"energy\", \"OPEC\", \"power\",\n",
    "    \"electricity\", \"green\", \"utilities\",\n",
    "\n",
    "    # Financials Sector\n",
    "    \"JPM\", \"BAC\", \"WFC\", \"AXP\", \"MS\",\n",
    "    \"JPMorgan\", \"Bank of America\", \"Wells Fargo\", \"American Express\", \"Morgan Stanley\",\n",
    "    \"bank\", \"interest rates\", \"savings\", \"investment\", \"regulation\",\n",
    "    \"inflation\", \"employment\", \"stock\", \"bond\", \"FED\",\n",
    "    \"SEC\", \"NYSE\", \"NASDAQ\", \"S&P500\",\n",
    "\n",
    "    # Tech Sector\n",
    "    \"MSFT\", \"AAPL\", \"NVDA\", \"GOOGL\", \"META\",\n",
    "    \"Microsoft\", \"Apple\", \"Nvidia\", \"Alphabet\", \"Meta\",\n",
    "    \"AI\", \"Google\", \"cybersecurity\", \"fintech\", \"data\", \"cloud\"\n",
    "]\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "    'Accept-Language': 'en-US,en;q=0.9',\n",
    "    'Accept-Encoding': 'gzip, deflate, br',\n",
    "    'Connection': 'keep-alive',\n",
    "    'Referer': 'https://www.ft.com/',\n",
    "    'Origin': 'https://www.ft.com'\n",
    "}\n",
    "\n",
    "for keyword in keywords:\n",
    "    keyurl = f\"https://www.ft.com/search?q={keyword}&page=1&sort=date&isFirstView=true\"\n",
    "\n",
    "\n",
    "    keyresult = requests.get(keyurl, headers=headers)\n",
    "\n",
    "    keyresult_content = keyresult.content\n",
    "    keysoup = BeautifulSoup(keyresult_content, \"html.parser\")\n",
    "    try:\n",
    "        maxpages = keysoup.find('span', {\"class\": \"search-pagination__page\"})\n",
    "        maxpages = int(maxpages.get_text(strip=True).split()[-1])\n",
    "    except (AttributeError, ValueError) as e:\n",
    "        print(f\"Skipping keyword '{keyword}' due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "    for page in range(1, maxpages):\n",
    "        url = f\"https://www.ft.com/search?q={keyword}&page={page}&sort=date&isFirstView=true\"\n",
    "        result = requests.get(url, headers=headers)\n",
    "        \n",
    "        if \"Sorry\" in result.text: # maybe unnecessary\n",
    "            print(f\"Stopping iteration: Page {page} is not available.\")\n",
    "            break\n",
    "        \n",
    "        result_content = result.content\n",
    "        soup = BeautifulSoup(result_content, \"lxml\")\n",
    "        \n",
    "        for article in soup.findAll(\"div\", {\"class\": \"o-teaser\"}):\n",
    "            heading = article.find(\"div\", {\"class\": \"o-teaser__heading\"}).get_text(strip=True)\n",
    "            link = article.find(\"div\", {\"class\": \"o-teaser__heading\"}).find('a', href=True)\n",
    "            date = article.find('time', {\"class\": \"o-teaser__timestamp-date\"})\n",
    "            \n",
    "            if heading and link and date:\n",
    "                if link not in collected_links:\n",
    "                    article_date = datetime.strptime(date.text.strip(), \"%B %d, %Y\")\n",
    "                    if article_date > cutoff_date:\n",
    "                        news_data.append([heading, link['href'], date.text.strip()])\n",
    "                        collected_links.add(link)\n",
    "\n",
    "print(f\"Total articles collected in news_data: {len(news_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625\n"
     ]
    }
   ],
   "source": [
    "print(len(news_data)) #625"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
